{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11563
        },
        "outputId": "0fc0a296-9a01-4a20-9f2e-ffa882d7057a"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(150,150,3),\n",
        "                               include_top=False,\n",
        "                               weights=None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layers.trainable=False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-31 13:29:26--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.127.128, 2a00:1450:4013:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.127.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep   8%[>                   ]   7.03M  35.2MB/s               \r        /tmp/incept  56%[==========>         ]  47.53M   119MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M   143MB/s    in 0.6s    \n",
            "\n",
            "2019-05-31 13:29:26 (143 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46d78b00-e658-40fd-8476-a99b5e885d2d"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8520
        },
        "outputId": "af564b1c-ee52-4ab3-9ec6-5374d8c1221c"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 47,493,665\n",
            "Non-trainable params: 18,816\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "1eb94ac5-e679-4db2-eca9-d178b7ea0151"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-31 13:30:13--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.127.128, 2a00:1450:4013:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.127.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  91.2MB/s    in 1.6s    \n",
            "\n",
            "2019-05-31 13:30:15 (91.2 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-05-31 13:30:18--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.127.128, 2a00:1450:4013:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.127.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-05-31 13:30:18 (127 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "84c72259-4606-49be-f3be-08e887719f1b"
      },
      "source": [
        "\n",
        "base_dir_train = '/tmp/training'\n",
        "base_dir_validate='/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(base_dir_train, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(base_dir_train, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(base_dir_validate, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(base_dir_validate, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0bd5a227-6c38-48d0-b80f-a5504cea5093"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes\n",
        "# Found 256 images belonging to 2 classes"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "7545e51a-fc1c-43a9-e8f0-3b8bae8dfc90"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    validation_data = validation_generator,\n",
        "    steps_per_epoch = 100,\n",
        "    epochs = 100,\n",
        "    validation_steps = 50,\n",
        "    verbose = 2,\n",
        "    callbacks=[callbacks])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 2s 185ms/step - loss: 0.6645 - acc: 0.8906\n",
            " - 23s - loss: 0.1630 - acc: 0.9426 - val_loss: 0.6645 - val_acc: 0.8906\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 0.0240 - acc: 0.9922\n",
            " - 12s - loss: 0.0287 - acc: 0.9873 - val_loss: 0.0240 - val_acc: 0.9922\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 1s 113ms/step - loss: 0.1200 - acc: 0.9531\n",
            " - 13s - loss: 0.0126 - acc: 0.9961 - val_loss: 0.1200 - val_acc: 0.9531\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 1s 114ms/step - loss: 0.6503 - acc: 0.9062\n",
            " - 13s - loss: 0.0096 - acc: 0.9971 - val_loss: 0.6503 - val_acc: 0.9062\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 2s 123ms/step - loss: 6.1931 - acc: 0.5703\n",
            " - 13s - loss: 0.0243 - acc: 0.9922 - val_loss: 6.1931 - val_acc: 0.5703\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 0.2876 - acc: 0.9453\n",
            " - 14s - loss: 0.0136 - acc: 0.9981 - val_loss: 0.2876 - val_acc: 0.9453\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 1s 114ms/step - loss: 0.4312 - acc: 0.9414\n",
            " - 13s - loss: 0.0057 - acc: 0.9971 - val_loss: 0.4312 - val_acc: 0.9414\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 0.9586 - acc: 0.8828\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            " - 13s - loss: 7.4495e-05 - acc: 1.0000 - val_loss: 0.9586 - val_acc: 0.8828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "cd253a5b-60c4-44c9-b148-c292a510fc9f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}